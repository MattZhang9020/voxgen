{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_dense(voxel_data, voxel_map_shape=(128, 128, 128), value=1.0):\n",
    "    dense_objs_voxel_data = []\n",
    "    \n",
    "    for obj_voxel_coordinates in voxel_data:\n",
    "        voxel_map = np.zeros(voxel_map_shape, dtype=np.float32)\n",
    "        voxel_map[tuple(obj_voxel_coordinates.T)] = value\n",
    "        dense_objs_voxel_data.append(voxel_map)\n",
    "        \n",
    "    return dense_objs_voxel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_obj_along_axis(voxel_coordinates, rotation_angle, axis, voxel_map_shape=(128, 128, 128)):\n",
    "    theta = np.radians(rotation_angle)\n",
    "    \n",
    "    if axis == 'x':\n",
    "        rot_matrix = np.array([[1, 0, 0],\n",
    "                                [0, np.cos(theta), -np.sin(theta)],\n",
    "                                [0, np.sin(theta), np.cos(theta)]])\n",
    "    elif axis == 'y':\n",
    "        rot_matrix = np.array([[np.cos(theta), 0, np.sin(theta)],\n",
    "                                [0, 1, 0],\n",
    "                                [-np.sin(theta), 0, np.cos(theta)]])\n",
    "    elif axis == 'z':\n",
    "        rot_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid axis. Must be 'x', 'y', or 'z'.\")\n",
    "        \n",
    "    center = np.array(voxel_map_shape) / 2\n",
    "    centered_coordinates = voxel_coordinates - center\n",
    "        \n",
    "    rotated_coords = np.dot(centered_coordinates, rot_matrix.T)\n",
    "    rotated_coords += center\n",
    "    \n",
    "    rotated_coords = np.round(rotated_coords).astype(int)\n",
    "    valid_indices = np.all((rotated_coords >= 0) & (rotated_coords < np.array(voxel_map_shape)), axis=1)\n",
    "    \n",
    "    rotated_coords = rotated_coords[valid_indices]\n",
    "\n",
    "    return rotated_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_rotate_obj_along_axis(voxel_coordinates, rotation_angle, axis, voxel_map_shape=(128, 128, 128)):\n",
    "    theta = rotation_angle * (np.pi / 180)\n",
    "\n",
    "    if axis == 'x':\n",
    "        rot_matrix = tf.stack([\n",
    "            tf.constant([1, 0, 0], dtype=tf.float32),\n",
    "            tf.stack([0, tf.cos(theta), -tf.sin(theta)], axis=0),\n",
    "            tf.stack([0, tf.sin(theta), tf.cos(theta)], axis=0)\n",
    "        ], axis=0)\n",
    "    elif axis == 'y':\n",
    "        rot_matrix = tf.stack([\n",
    "            tf.stack([tf.cos(theta), 0, tf.sin(theta)], axis=0),\n",
    "            tf.constant([0, 1, 0], dtype=tf.float32),\n",
    "            tf.stack([-tf.sin(theta), 0, tf.cos(theta)], axis=0)\n",
    "        ], axis=0)\n",
    "    elif axis == 'z':\n",
    "        rot_matrix = tf.stack([\n",
    "            tf.stack([tf.cos(theta), -tf.sin(theta), 0], axis=0),\n",
    "            tf.stack([tf.sin(theta), tf.cos(theta), 0], axis=0),\n",
    "            tf.constant([0, 0, 1], dtype=tf.float32)\n",
    "        ], axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid axis. Must be 'x', 'y', or 'z'.\")\n",
    "    \n",
    "    center = tf.expand_dims(tf.cast(tf.constant(voxel_map_shape, dtype=tf.float32) / 2, tf.float32), 0)\n",
    "    center = tf.tile(center, [tf.shape(voxel_coordinates)[0], 1])\n",
    "        \n",
    "    centered_coordinates = voxel_coordinates - center\n",
    "\n",
    "    rotated_coords = tf.matmul(centered_coordinates, rot_matrix, transpose_b=True)\n",
    "    rotated_coords += center\n",
    "\n",
    "    rotated_coords = tf.round(rotated_coords)\n",
    "\n",
    "    valid_indices = tf.reduce_all((rotated_coords >= 0) & (rotated_coords < tf.constant(voxel_map_shape, dtype=tf.float32)), axis=1)\n",
    "    \n",
    "    rotated_coords = tf.boolean_mask(rotated_coords, valid_indices)\n",
    "\n",
    "    return rotated_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_project_to_silhouette(voxels, img_wh=128):\n",
    "    voxels = tf.reshape(voxels, voxels.shape[:-1])\n",
    "\n",
    "    batch_size = tf.shape(voxels)[0]\n",
    "    projection_planes = tf.TensorArray(tf.int32, size=batch_size, dynamic_size=False, infer_shape=False)\n",
    "\n",
    "    for i in tf.range(batch_size):\n",
    "        angles = tf.random.uniform((3,), 0, 360)\n",
    "        axis = ['x', 'y', 'z']\n",
    "\n",
    "        voxel_coords = tf.where(voxels[i] >= 0.5)\n",
    "        voxel_coords = tf.cast(voxel_coords, tf.float32)\n",
    "\n",
    "        rotated_coords = voxel_coords\n",
    "\n",
    "        for j in range(len(angles)):\n",
    "            rotated_coords = tf_rotate_obj_along_axis(rotated_coords, angles[j], axis[j])\n",
    "\n",
    "        x = rotated_coords[:, 0]\n",
    "        y = rotated_coords[:, 1]\n",
    "\n",
    "        valid_x = tf.logical_and(x < img_wh, x >= 0)\n",
    "        valid_y = tf.logical_and(y < img_wh, y >= 0)\n",
    "        valid_coords = tf.logical_and(valid_x, valid_y)\n",
    "\n",
    "        x_valid = tf.boolean_mask(x, valid_coords)\n",
    "        y_valid = tf.boolean_mask(y, valid_coords)\n",
    "\n",
    "        indices = tf.cast(tf.stack((y_valid, x_valid), axis=1), tf.int32)\n",
    "        updates = tf.ones_like(x_valid, dtype=tf.int32)\n",
    "        projection_plane = tf.tensor_scatter_nd_update(tf.zeros((img_wh, img_wh), dtype=tf.int32), indices, updates)\n",
    "        projection_planes = projection_planes.write(i, projection_plane)\n",
    "\n",
    "    return projection_planes.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, dataset_dir_pth, each_chair_parts_count_pth, objs_count=None, voxel_map_shape=(128, 128, 128), batch_size=4):\n",
    "        self.dataset_dir_pth = dataset_dir_pth\n",
    "        \n",
    "        self.each_chair_parts_count = np.load(each_chair_parts_count_pth)[:objs_count]\n",
    "        self.num_objts = objs_count\n",
    "        \n",
    "        self.data_names = np.array(sorted_alphanumeric(os.listdir(self.dataset_dir_pth)), dtype=str)[:self._get_total_parts_size()]\n",
    "        self.num_parts = len(self.data_names)\n",
    "        \n",
    "        self.curr_index = 0\n",
    "        self.indexes = np.arange(self.num_parts)\n",
    "        \n",
    "        self.voxel_map_shape = voxel_map_shape\n",
    "        \n",
    "        self.batch_szie = batch_size\n",
    "        \n",
    "        self.voxel_data_sparse = self._load_voxel_data()\n",
    "    \n",
    "    def _get_total_parts_size(self):\n",
    "        count = 0\n",
    "        \n",
    "        if self.num_objts == None:\n",
    "            return None\n",
    "        \n",
    "        for i in range(self.num_objts):\n",
    "            count += self.each_chair_parts_count[i]\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def _load_voxel_data(self):\n",
    "        voxel_data_sparse = []\n",
    "        for data_name in tqdm(self.data_names, desc=\"Loading Voxel Data\"):\n",
    "            data_pth = os.path.join(self.dataset_dir_pth, data_name)\n",
    "            voxel_data_sparse.append(np.load(data_pth))\n",
    "        return voxel_data_sparse\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.curr_index >= len(self.indexes):\n",
    "            self.curr_index = 0\n",
    "            raise StopIteration\n",
    "        \n",
    "        indexes = []\n",
    "        \n",
    "        for i in range(self.curr_index, self.curr_index + self.batch_szie):\n",
    "            if i >= len(self.indexes):\n",
    "                break\n",
    "            indexes.append(i)\n",
    "        \n",
    "        sparse_data = self._load_batched_sparse_data(indexes)\n",
    "        \n",
    "        self.curr_index += self.batch_szie\n",
    "        \n",
    "        return indexes, sparse_data\n",
    "    \n",
    "    def _load_batched_sparse_data(self, indexes):\n",
    "        voxel_data_sparse = []\n",
    "        \n",
    "        for i in indexes:\n",
    "            voxel_data_sparse.append(self.voxel_data_sparse[i])\n",
    "            \n",
    "        return voxel_data_sparse\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.curr_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EACH_CHAIR_PARTS_COUNT_PTH = \".\\\\dataset\\\\each_chair_parts_count.npy\"\n",
    "DATASET_DIR_PTH = \".\\\\dataset\\\\chair_voxel_data\"\n",
    "\n",
    "LOAD_OBJS_COUNT = 1\n",
    "VOXEL_MAP_SHAPE = (128, 128, 128)\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(dataset_dir_pth=DATASET_DIR_PTH,\n",
    "                               each_chair_parts_count_pth=EACH_CHAIR_PARTS_COUNT_PTH,\n",
    "                               objs_count=LOAD_OBJS_COUNT,\n",
    "                               voxel_map_shape=VOXEL_MAP_SHAPE,\n",
    "                               batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeometryNetwork:\n",
    "    def __init__(self, hparam):\n",
    "        self.latent_code_dim = hparam['model_latent_code_dim']\n",
    "\n",
    "        self.fc_channels = hparam['model_fc_channels']\n",
    "\n",
    "        self.conv_size = hparam['model_conv_size']\n",
    "\n",
    "        self.num_latent_codes_parts = hparam['model_num_latent_codes_parts']\n",
    "        self.num_latent_codes_objts = hparam['model_num_latent_codes_objts']\n",
    "\n",
    "        self.learning_rate_network = hparam['model_learning_rate_network']\n",
    "        self.learning_rate_codes = hparam['model_learning_rate_codes']\n",
    "\n",
    "        self.model_voxel_map_shape = hparam['model_voxel_map_shape']\n",
    "\n",
    "        self.checkpoint_dir = hparam['model_checkpoint_dir']\n",
    "        \n",
    "        self.ramdom_projection_num = hparam['modelramdom_projection_num']\n",
    "\n",
    "        self._init_model()\n",
    "        self._init_optimizer()\n",
    "        self._init_losser()\n",
    "        self._init_checkpoint()\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.part_generator = self._get_generator()\n",
    "        self.objt_generator = self._get_generator()\n",
    "\n",
    "        init_latent_code_parts = tf.random.normal((self.num_latent_codes_parts, self.latent_code_dim))\n",
    "        self.latent_code_vars_parts = tf.Variable(init_latent_code_parts, trainable=True)\n",
    "\n",
    "        init_latent_code_objts = tf.random.normal((self.num_latent_codes_objts, self.latent_code_dim))\n",
    "        self.latent_code_vars_objts = tf.Variable(init_latent_code_objts, trainable=True)\n",
    "\n",
    "        self.part_generator_trainable_variables = self.part_generator.trainable_variables\n",
    "        self.objt_generator_trainable_variables = self.objt_generator.trainable_variables\n",
    "\n",
    "    def _get_generator(self):\n",
    "\n",
    "        with tf.name_scope('Network/'):\n",
    "\n",
    "            latent_code = tf.keras.layers.Input(shape=(self.latent_code_dim,))\n",
    "\n",
    "            with tf.name_scope('FC_layers'):\n",
    "\n",
    "                fc0 = tf.keras.layers.Dense(self.fc_channels, activation='relu')(latent_code)\n",
    "\n",
    "                fc1 = tf.keras.layers.Dense(self.fc_channels, activation='relu')(fc0)\n",
    "\n",
    "                fc2 = tf.keras.layers.Dense(self.fc_channels, activation='relu')(fc1)\n",
    "\n",
    "                fc2_as_volume = tf.keras.layers.Reshape((1, 1, 1, self.fc_channels))(fc2)\n",
    "\n",
    "            with tf.name_scope('GLO_VoxelDecoder'):\n",
    "\n",
    "                decoder_1 = self._conv_t_block_3d(fc2_as_volume, num_filters=32, size=self.conv_size, strides=2)\n",
    "\n",
    "                decoder_2 = self._conv_t_block_3d(decoder_1, num_filters=32, size=self.conv_size, strides=2)\n",
    "\n",
    "                decoder_3 = self._conv_t_block_3d(decoder_2, num_filters=32, size=self.conv_size, strides=2)\n",
    "\n",
    "                decoder_4 = self._conv_t_block_3d(decoder_3, num_filters=16, size=self.conv_size, strides=2)\n",
    "\n",
    "                decoder_5 = self._conv_t_block_3d(decoder_4, num_filters=8, size=self.conv_size, strides=2)\n",
    "\n",
    "                decoder_6 = self._conv_t_block_3d(decoder_5, num_filters=4, size=self.conv_size, strides=2)\n",
    "\n",
    "                volume_out = self._conv_t_block_3d(decoder_6, num_filters=1, size=self.conv_size, strides=2, output_mode=True)\n",
    "\n",
    "        return tf.keras.Model(inputs=[latent_code], outputs=[volume_out])\n",
    "\n",
    "    def _conv_t_block_3d(self, tensor, num_filters, size, strides, alpha_lrelu=0.2, output_mode=False):\n",
    "        conv_3D_transpose = tf.keras.layers.Conv3DTranspose(\n",
    "            filters=num_filters,\n",
    "            kernel_size=size,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "            use_bias=False\n",
    "        )\n",
    "\n",
    "        tensor = conv_3D_transpose(tensor)\n",
    "\n",
    "        if output_mode:\n",
    "            return tensor\n",
    "\n",
    "        tensor = tf.keras.layers.BatchNormalization()(tensor)\n",
    "\n",
    "        tensor = tf.keras.layers.LeakyReLU(alpha=alpha_lrelu)(tensor)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def _init_optimizer(self):\n",
    "        self.optimizer_part_generator = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_network)\n",
    "        self.optimizer_objt_generator = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_network)\n",
    "        self.optimizer_latent_for_parts = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_codes)\n",
    "        self.optimizer_latent_for_objts = tf.keras.optimizers.Adam(learning_rate=self.learning_rate_codes)\n",
    "\n",
    "    def _init_losser(self):\n",
    "        self.losser_bce = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    def _init_checkpoint(self):\n",
    "        self.checkpoint = tf.train.Checkpoint(\n",
    "            part_generator=self.part_generator,\n",
    "            objt_generator=self.objt_generator,\n",
    "            latent_code_vars_parts=self.latent_code_vars_parts,\n",
    "            latent_code_vars_objts=self.latent_code_vars_objts,\n",
    "            optimizer_part_generator=self.optimizer_part_generator,\n",
    "            optimizer_objt_generator=self.optimizer_objt_generator,\n",
    "            optimizer_latent_for_parts=self.optimizer_latent_for_parts,\n",
    "            optimizer_latent_for_objts=self.optimizer_latent_for_objts\n",
    "        )\n",
    "\n",
    "        self.manager = tf.train.CheckpointManager(checkpoint=self.checkpoint,\n",
    "                                                  directory=self.checkpoint_dir,\n",
    "                                                  max_to_keep=1)\n",
    "\n",
    "        self._load_checkpoint()\n",
    "\n",
    "    def _load_checkpoint(self):\n",
    "        latest_checkpoint = self.manager.latest_checkpoint\n",
    "\n",
    "        if latest_checkpoint is not None:\n",
    "            print('Checkpoint {} restored'.format(latest_checkpoint))\n",
    "        else:\n",
    "            print('No checkpoint was restored.')\n",
    "\n",
    "        self.checkpoint.restore(latest_checkpoint).expect_partial()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step_parts(self, latent_code_vars, true_voxels_part):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_logits_voxels = self.part_generator(latent_code_vars)\n",
    "\n",
    "            pred_voxels_part = tf.sigmoid(pred_logits_voxels)\n",
    "            \n",
    "            loss = self.losser_bce(true_voxels_part, pred_voxels_part)\n",
    "\n",
    "        network_vars = self.part_generator_trainable_variables\n",
    "        gradients = tape.gradient(loss, network_vars + [latent_code_vars])\n",
    "\n",
    "        self.optimizer_part_generator.apply_gradients(zip(gradients[:len(network_vars)], network_vars))\n",
    "        self.optimizer_latent_for_parts.apply_gradients(zip(gradients[len(network_vars):], [latent_code_vars]))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step_objts(self, latent_code_vars, true_voxels_objt):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_logits_voxels = self.objt_generator(latent_code_vars)\n",
    "            \n",
    "            pred_voxels_objt = tf.sigmoid(pred_logits_voxels)\n",
    "            \n",
    "            bce_loss = self.losser_bce(true_voxels_objt, pred_voxels_objt)\n",
    "            \n",
    "            silhouette_losses = []\n",
    "                        \n",
    "            for _ in range(self.ramdom_projection_num):\n",
    "                true_silhouette = tf_project_to_silhouette(true_voxels_objt)\n",
    "                pred_silhouette = tf_project_to_silhouette(pred_voxels_objt)\n",
    "                silhouette_losses.append(tf.math.reduce_euclidean_norm((true_silhouette, pred_silhouette)))\n",
    "            \n",
    "            silhouette_loss = tf.reduce_mean(tf.convert_to_tensor(silhouette_losses, dtype=tf.float32))\n",
    "            \n",
    "            loss = bce_loss + silhouette_loss\n",
    "\n",
    "        network_vars = self.objt_generator_trainable_variables\n",
    "        gradients = tape.gradient(loss, network_vars + [latent_code_vars])\n",
    "        \n",
    "        self.optimizer_objt_generator.apply_gradients(zip(gradients[:len(network_vars)], network_vars))\n",
    "        self.optimizer_latent_for_objts.apply_gradients(zip(gradients[len(network_vars):], [latent_code_vars]))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step_assamble(self, latent_code_vars, true_voxels_objt, model='part'):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_logits_voxels = self.part_generator(latent_code_vars)\n",
    "            \n",
    "            pred_voxels = tf.sigmoid(pred_logits_voxels)\n",
    "            \n",
    "            pred_voxels_objt = tf.math.reduce_sum(pred_voxels, axis=0)\n",
    "\n",
    "            loss = self.losser_bce(true_voxels_objt, pred_voxels_objt)\n",
    "\n",
    "        gradients = tape.gradient(loss, [latent_code_vars])\n",
    "\n",
    "        self.optimizer_latent_for_parts.apply_gradients(zip(gradients, [latent_code_vars]))\n",
    "\n",
    "        return pred_voxels, loss\n",
    "\n",
    "    def update_latent_code_vars_parts(self, latent_code_vars):\n",
    "        self.latent_code_vars_parts.assign(latent_code_vars)\n",
    "    \n",
    "    def update_latent_code_vars_objts(self, latent_code_vars):\n",
    "        self.latent_code_vars_objts.assign(latent_code_vars)\n",
    "\n",
    "    def save_models(self):\n",
    "        self.manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hparam = {\n",
    "    'model_latent_code_dim': 256,\n",
    "    'model_fc_channels': 512,\n",
    "    'model_conv_size': 4,\n",
    "    'model_num_latent_codes_parts': data_generator.num_parts,\n",
    "    'model_num_latent_codes_objts': data_generator.num_objts,\n",
    "    'model_learning_rate_network': 5e-4,\n",
    "    'model_learning_rate_codes': 1e-3,\n",
    "    'model_voxel_map_shape': VOXEL_MAP_SHAPE,\n",
    "    'model_checkpoint_dir': './ckpt',\n",
    "    'modelramdom_projection_num': 5\n",
    "}\n",
    "\n",
    "geom_network = GeometryNetwork(model_hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPOCH_FOR_PARTS = 1500\n",
    "\n",
    "pbar = tqdm(range(1, TRAINING_EPOCH_FOR_PARTS+1), desc=\"Training on Parts\")\n",
    "\n",
    "data_generator.reset_index()\n",
    "\n",
    "for epoch in pbar:\n",
    "    total_loss = []\n",
    "    \n",
    "    latent_code_vars_parts = geom_network.latent_code_vars_parts.numpy()\n",
    "    \n",
    "    for voxel_index, true_voxels in data_generator:\n",
    "        true_voxels = data_to_dense(true_voxels)\n",
    "                                \n",
    "        latent_code_vars = tf.Variable(latent_code_vars_parts[voxel_index], trainable=True)\n",
    "        \n",
    "        true_voxels = np.expand_dims(true_voxels, axis=-1)\n",
    "                \n",
    "        loss = geom_network.train_step_parts(latent_code_vars, true_voxels).numpy()\n",
    "        \n",
    "        latent_code_vars_parts[voxel_index] = latent_code_vars.numpy()\n",
    "        \n",
    "        total_loss.append(loss)\n",
    "                \n",
    "    pbar.set_postfix({\"Avg Loss\": '{:.9f}'.format(sum(total_loss) / len(total_loss))})\n",
    "    \n",
    "    geom_network.update_latent_code_vars_parts(latent_code_vars_parts)\n",
    "    \n",
    "geom_network.objt_generator.set_weights(geom_network.part_generator.get_weights())\n",
    "\n",
    "geom_network.save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_target_part = random.randint(0, data_generator.num_parts-1)\n",
    "\n",
    "test_target_part = 0\n",
    "\n",
    "true_voxels_coords = np.load(os.path.join(DATASET_DIR_PTH, str(test_target_part)+'.npy'))\n",
    "\n",
    "true_voxel_rotated_coords = rotate_obj_along_axis(true_voxels_coords, rotation_angle=180, axis='y')\n",
    "true_voxel_rotated = data_to_dense([true_voxel_rotated_coords])[0]\n",
    "\n",
    "true_voxel_rotated_plot = np.moveaxis(true_voxel_rotated, 1, -1)\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "ax.voxels(true_voxel_rotated_plot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "latent_codes = tf.expand_dims(geom_network.latent_code_vars_parts[test_target_part], axis=0)\n",
    "\n",
    "pred_logits_voxels = geom_network.part_generator(latent_codes)\n",
    "pred_voxels = tf.sigmoid(pred_logits_voxels)\n",
    "pred_voxels = tf.cast(tf.math.greater_equal(pred_voxels, 0.3), tf.float32).numpy()\n",
    "pred_voxels = pred_voxels[0, :, :, :].reshape((pred_voxels.shape[1:4]))\n",
    "pred_voxel_coords = np.where(pred_voxels == True)\n",
    "\n",
    "x, y, z = pred_voxel_coords\n",
    "pred_voxel_coords = np.expand_dims(x, axis=0).T\n",
    "pred_voxel_coords = np.concatenate((pred_voxel_coords, np.expand_dims(y, axis=0).T), axis=1)\n",
    "pred_voxel_coords = np.concatenate((pred_voxel_coords, np.expand_dims(z, axis=0).T), axis=1)\n",
    "\n",
    "pred_voxel_rotated_coords = rotate_obj_along_axis(pred_voxel_coords, rotation_angle=180, axis='y')\n",
    "pred_voxel_rotated = data_to_dense([pred_voxel_rotated_coords])[0]\n",
    "\n",
    "pred_voxel_rotated_plot = np.moveaxis(pred_voxel_rotated, 1, -1)\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "ax.voxels(pred_voxel_rotated_plot)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPOCH_FOR_OBJTS = 3000\n",
    "\n",
    "pbar = tqdm(range(1, TRAINING_EPOCH_FOR_OBJTS+1), desc=\"Training on Objects\")\n",
    "\n",
    "latent_code_vars_parts = geom_network.latent_code_vars_parts.numpy()\n",
    "latent_code_vars_objts = []\n",
    "\n",
    "base_index = 0\n",
    "\n",
    "for obj_index, count in enumerate(data_generator.each_chair_parts_count):\n",
    "    reduced_latent_code_vars = np.mean(latent_code_vars_parts[base_index:base_index+count], axis=0)\n",
    "    latent_code_vars_objts.append(reduced_latent_code_vars)\n",
    "    base_index += count\n",
    "\n",
    "geom_network.update_latent_code_vars_objts(tf.Variable(latent_code_vars_objts, trainable=True))\n",
    "\n",
    "data_generator.reset_index()\n",
    "\n",
    "for epoch in pbar:\n",
    "    total_loss = []\n",
    "    \n",
    "    latent_code_vars_objts = geom_network.latent_code_vars_objts.numpy()\n",
    "    \n",
    "    range_count = 0\n",
    "    \n",
    "    for obj_index, count in enumerate(data_generator.each_chair_parts_count):        \n",
    "        latent_code_vars = tf.Variable(tf.expand_dims(latent_code_vars_objts[obj_index], axis=0), trainable=True)\n",
    "        \n",
    "        true_voxels = np.zeros(shape=(VOXEL_MAP_SHAPE), dtype=np.float32)\n",
    "        \n",
    "        range_count += count\n",
    "        for voxel_index, sparse_data in data_generator:\n",
    "            for x, y, z in sparse_data[0]:\n",
    "                true_voxels[x, y, z] = 1\n",
    "                \n",
    "            if voxel_index == range_count-1:\n",
    "                if voxel_index == data_generator.num_parts-1:\n",
    "                    data_generator.reset_index()\n",
    "                break\n",
    "        \n",
    "        true_voxels = np.expand_dims(true_voxels, axis=(0, -1))\n",
    "                \n",
    "        loss = geom_network.train_step_objts(latent_code_vars, true_voxels)\n",
    "                        \n",
    "        total_loss.append(loss)\n",
    "        \n",
    "    pbar.set_postfix({\"Avg Loss\": '{:.9f}'.format(sum(total_loss) / len(total_loss))})\n",
    "    \n",
    "    geom_network.update_latent_code_vars_objts(latent_code_vars_objts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_obj = 0\n",
    "\n",
    "base_index = 0\n",
    "\n",
    "for i in range(test_target_obj):\n",
    "    base_index += data_generator.each_chair_parts_count[i]\n",
    "\n",
    "true_voxels = np.zeros(shape=(VOXEL_MAP_SHAPE), dtype=np.int32)\n",
    "\n",
    "for i in range(base_index, base_index+data_generator.each_chair_parts_count[test_target_obj]):\n",
    "    true_voxels_coords = np.load(os.path.join(DATASET_DIR_PTH, str(i)+'.npy'))\n",
    "    \n",
    "    for x, y, z in true_voxels_coords:\n",
    "        true_voxels[x, y, z] = 1\n",
    "\n",
    "true_voxels = tf.convert_to_tensor(np.expand_dims(true_voxels, axis=(0, -1)), dtype=tf.float32)\n",
    "\n",
    "silhouette = tf.reverse(tf_project_to_silhouette(true_voxels)[0], axis=[0])\n",
    "\n",
    "plt.imshow(silhouette, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_target_obj = random.randint(0, data_generator.num_objts-1)\n",
    "\n",
    "test_target_obj = 0\n",
    "\n",
    "base_index = 0\n",
    "\n",
    "for i in range(test_target_obj):\n",
    "    base_index += data_generator.each_chair_parts_count[i]\n",
    "\n",
    "true_voxels = np.zeros(shape=(VOXEL_MAP_SHAPE), dtype=np.int32)\n",
    "\n",
    "for i in range(base_index, base_index+data_generator.each_chair_parts_count[test_target_obj]):\n",
    "    true_voxels_coords = np.load(os.path.join(DATASET_DIR_PTH, str(i)+'.npy'))\n",
    "    \n",
    "    for x, y, z in true_voxels_coords:\n",
    "        true_voxels[x, y, z] = 1\n",
    "\n",
    "true_voxels_coords = np.where(true_voxels == 1)\n",
    "\n",
    "x, y, z = true_voxels_coords\n",
    "true_voxels_coords = np.expand_dims(x, axis=0).T\n",
    "true_voxels_coords = np.concatenate((true_voxels_coords, np.expand_dims(y, axis=0).T), axis=1)\n",
    "true_voxels_coords = np.concatenate((true_voxels_coords, np.expand_dims(z, axis=0).T), axis=1)\n",
    "\n",
    "true_voxel_rotated_coords = rotate_obj_along_axis(true_voxels_coords, rotation_angle=180, axis='y')\n",
    "true_voxel_rotated = data_to_dense([true_voxel_rotated_coords])[0]\n",
    "\n",
    "true_voxel_rotated_plot = np.moveaxis(true_voxel_rotated, 1, -1)\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "ax.voxels(true_voxel_rotated_plot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('./{}_true_voxel'.format(str(test_target_obj)) + '.png', dpi=300)\n",
    "\n",
    "latent_codes = tf.expand_dims(geom_network.latent_code_vars_objts[test_target_obj], axis=0)\n",
    "\n",
    "pred_logits_voxels = geom_network.objt_generator(latent_codes)\n",
    "pred_voxels = tf.sigmoid(pred_logits_voxels)\n",
    "pred_voxels = tf.cast(tf.math.greater_equal(pred_voxels, 0.3), tf.float32).numpy()\n",
    "pred_voxels = pred_voxels[0, :, :, :].reshape((pred_voxels.shape[1:4]))\n",
    "pred_voxels_coords = np.where(pred_voxels == True)\n",
    "\n",
    "x, y, z = pred_voxels_coords\n",
    "pred_voxels_coords = np.expand_dims(x, axis=0).T\n",
    "pred_voxels_coords = np.concatenate((pred_voxels_coords, np.expand_dims(y, axis=0).T), axis=1)\n",
    "pred_voxels_coords = np.concatenate((pred_voxels_coords, np.expand_dims(z, axis=0).T), axis=1)\n",
    "\n",
    "pred_voxel_rotated_coords = rotate_obj_along_axis(pred_voxels_coords, rotation_angle=180, axis='y')\n",
    "pred_voxel_rotated = data_to_dense([pred_voxel_rotated_coords])[0]\n",
    "\n",
    "pred_voxel_rotated_plot = np.moveaxis(pred_voxel_rotated, 1, -1)\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "ax.voxels(pred_voxel_rotated_plot)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('./{}_pred_voxel'.format(str(test_target_obj)) + '.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(epoch, pred_voxels, palette):\n",
    "    pred_voxels = tf.cast(tf.math.greater_equal(pred_voxels, 0.3), tf.float32).numpy()\n",
    "    pred_voxels = pred_voxels.reshape((pred_voxels.shape[:4]))\n",
    "\n",
    "    voxels = np.zeros(shape=VOXEL_MAP_SHAPE, dtype=np.int32)\n",
    "    colors = np.zeros(shape=(*VOXEL_MAP_SHAPE, 3), dtype=np.float32)\n",
    "    \n",
    "    for i, part in enumerate(pred_voxels):\n",
    "        pred_voxel_coordinates = np.where(part == True)\n",
    "        \n",
    "        x, y, z = pred_voxel_coordinates\n",
    "        pred_voxel_coordinates = np.expand_dims(x, axis=0).T\n",
    "        pred_voxel_coordinates = np.concatenate((pred_voxel_coordinates, np.expand_dims(y, axis=0).T), axis=1)\n",
    "        pred_voxel_coordinates = np.concatenate((pred_voxel_coordinates, np.expand_dims(z, axis=0).T), axis=1)\n",
    "        \n",
    "        for coordinates in rotate_obj_along_axis(true_voxels_coords, rotation_angle=180, axis='y'):\n",
    "            x, y, z = coordinates\n",
    "            voxels[x, y, z] = 1\n",
    "            colors[x, y, z] = palette[i]\n",
    "\n",
    "    voxels = np.moveaxis(voxels, 1, -1)\n",
    "    colors = np.moveaxis(colors, 1, -2)\n",
    "\n",
    "    ax = plt.figure().add_subplot(projection='3d')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.voxels(voxels, facecolors=colors)\n",
    "\n",
    "    plt.savefig('./gif_imgs/{}_pred_parts'.format(str(epoch)) + '.png', dpi=300)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPOCH_FOR_OBJTS = 1500\n",
    "\n",
    "USER_DEFINE_PARTS_NUM = 30\n",
    "\n",
    "latent_code_vars = tf.Variable(tf.random.normal((USER_DEFINE_PARTS_NUM, geom_network.latent_code_dim)), trainable=True)\n",
    "\n",
    "pbar = tqdm(range(1, TRAINING_EPOCH_FOR_OBJTS+1), desc=\"Training on Assambles\")\n",
    "\n",
    "data_generator.reset_index()\n",
    "\n",
    "palette = [np.array([random.random() for _ in range(3)], dtype=np.float32) for __ in range(USER_DEFINE_PARTS_NUM)]\n",
    "\n",
    "target_object = 0\n",
    "\n",
    "for epoch in pbar:\n",
    "    total_loss = []\n",
    "    \n",
    "    start_count = 0\n",
    "    for i in range(target_object):\n",
    "        start_count += data_generator.each_chair_parts_count[i]\n",
    "        \n",
    "    range_count = start_count + data_generator.each_chair_parts_count[target_object]\n",
    "                                            \n",
    "    true_voxels = np.zeros(shape=(VOXEL_MAP_SHAPE), dtype=np.float32)\n",
    "    \n",
    "    for voxel_index, sparse_data in data_generator: # finding parts is slow here, not a good idea, but works.\n",
    "        if voxel_index >= start_count:\n",
    "            for x, y, z in sparse_data[0]:\n",
    "                true_voxels[x, y, z] = 1\n",
    "            \n",
    "        if voxel_index == range_count-1:\n",
    "            data_generator.reset_index()\n",
    "            break\n",
    "                                            \n",
    "    true_voxels = tf.convert_to_tensor(np.expand_dims(true_voxels, axis=-1), dtype=tf.float32)\n",
    "                                            \n",
    "    pred_voxels, loss = geom_network.train_step_assamble(latent_code_vars, true_voxels)\n",
    "    \n",
    "    # if epoch % 10 == 0:\n",
    "    #     save_plot(epoch, pred_voxels, palette)\n",
    "                    \n",
    "    total_loss.append(loss.numpy())\n",
    "        \n",
    "    pbar.set_postfix({\"Avg Loss\": '{:.9f}'.format(sum(total_loss) / len(total_loss))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_codes = latent_code_vars.numpy()\n",
    "\n",
    "pred_logits_voxels = geom_network.part_generator(latent_codes)\n",
    "pred_voxels = tf.sigmoid(pred_logits_voxels)\n",
    "pred_voxels = tf.cast(tf.math.greater_equal(pred_voxels, 0.3), tf.float32).numpy()\n",
    "pred_voxels = pred_voxels.reshape((pred_voxels.shape[:4]))\n",
    "\n",
    "voxels = np.zeros(shape=VOXEL_MAP_SHAPE, dtype=np.int32)\n",
    "colors = np.zeros(shape=(*VOXEL_MAP_SHAPE, 3), dtype=np.float32)\n",
    "\n",
    "for part in pred_voxels:\n",
    "    pred_voxel_coords = np.where(part == True)\n",
    "    \n",
    "    x, y, z = pred_voxel_coords\n",
    "    pred_voxel_coords = np.expand_dims(x, axis=0).T\n",
    "    pred_voxel_coords = np.concatenate((pred_voxel_coords, np.expand_dims(y, axis=0).T), axis=1)\n",
    "    pred_voxel_coords = np.concatenate((pred_voxel_coords, np.expand_dims(z, axis=0).T), axis=1)\n",
    "    \n",
    "    color = np.array([random.random() for _ in range(3)], dtype=np.float32)\n",
    "    \n",
    "    for coordinates in rotate_obj_along_axis(pred_voxel_coords, rotation_angle=180, axis='y'):\n",
    "        x, y, z = coordinates\n",
    "        voxels[x, y, z] = 1\n",
    "        colors[x, y, z] = color\n",
    "\n",
    "voxels = np.moveaxis(voxels, 1, -1)\n",
    "colors = np.moveaxis(colors, 1, -2)\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "ax.voxels(voxels, facecolors=colors)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('./{}_pred_parts'.format(str(0)) + '.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = sorted_alphanumeric(os.listdir('C:\\\\Users\\\\Matt\\\\Downloads\\\\Voxgen\\\\gif_imgs'))\n",
    "\n",
    "gif_name = './voxgen_part.gif'\n",
    "\n",
    "frames = []\n",
    "for image_name in img_list:\n",
    "    frames.append(imageio.imread(os.path.join('./gif_imgs', image_name)))\n",
    "imageio.mimsave(gif_name, frames, 'GIF', duration=1, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
